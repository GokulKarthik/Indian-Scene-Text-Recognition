{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'Hindi'\n",
    "data_dir = f'Data/{language}'\n",
    "train_dir = f'{data_dir}/Train'\n",
    "val_dir = f'{data_dir}/Val'\n",
    "test_dir = f'{data_dir}/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_df_fp = f'Data/Characters/Characters-{language}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = os.cpu_count()\n",
    "print(cpu_count)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define character class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_df = pd.read_csv(character_df_fp)\n",
    "print(character_df.shape)\n",
    "character_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#character_df[character_df['Consonant']==\"-\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set()\n",
    "for character in character_df['Character'].values:\n",
    "    characters.update(list(character))\n",
    "characters = [\"-\"] + sorted(list(characters))\n",
    "print(len(characters))\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2char = {k:v for k,v in enumerate(characters)}\n",
    "print(idx2char)\n",
    "char2idx = {v:k for k,v in idx2char.items()}\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Define data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndianSceneTextDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data_dir):\n",
    "        self.data_dir = data_dir\n",
    "        self.image_fns = os.listdir(data_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_fns)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_fn = self.image_fns[index]\n",
    "        image_fp = os.path.join(self.data_dir, image_fn)\n",
    "        image = Image.open(image_fp).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        text = image_fn.split(\"_\")[0][:13]\n",
    "        return image, text, image_fn\n",
    "    \n",
    "    def transform(self, image):\n",
    "        \n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = IndianSceneTextDataset(train_dir) \n",
    "valset = IndianSceneTextDataset(val_dir) \n",
    "testset = IndianSceneTextDataset(test_dir) \n",
    "print(len(trainset), len(valset), len(testset))\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=16, num_workers=os.cpu_count(), shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=16, num_workers=os.cpu_count(), shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=16, num_workers=os.cpu_count(), shuffle=False)\n",
    "print(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, text_batch, image_fn_batch = iter(train_loader).next()\n",
    "print(image_batch.size())\n",
    "print(text_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "\n",
    "    text_tokens = list(text)\n",
    "    \n",
    "    return text_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in text_batch:\n",
    "    print(text, tokenize(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet18(pretrained=True)\n",
    "#print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in resnet.parameters():\n",
    "    pass#p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_chars, rnn_hidden_size=256):\n",
    "        \n",
    "        super(CRNN, self).__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.dp1 = nn.Dropout(p=0.5)\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        self.dp3 = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # CNN Part 1\n",
    "        resnet_modules = list(resnet.children())[:-3]\n",
    "        self.cnn_p1 = nn.Sequential(*resnet_modules)\n",
    "        \n",
    "        # CNN Part 2\n",
    "        self.cnn_p2 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.linear1 = nn.Linear(1024, 256)\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn1 = nn.GRU(input_size=rnn_hidden_size, \n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            bidirectional=True, \n",
    "                            num_layers=2,\n",
    "                            batch_first=True)\n",
    "        self.rnn2 = nn.GRU(input_size=rnn_hidden_size, \n",
    "                            hidden_size=rnn_hidden_size,\n",
    "                            bidirectional=True,\n",
    "                            num_layers=1, \n",
    "                            batch_first=True)\n",
    "        self.linear2 = nn.Linear(self.rnn_hidden_size*2, num_chars)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        batch = self.cnn_p1(batch)\n",
    "        # print(batch.size()) # torch.Size([-1, 256, 4, 13])\n",
    "        \n",
    "        batch = self.cnn_p2(batch) # [batch_size, channels, height, width]\n",
    "        batch = self.dp1(batch)\n",
    "        # print(batch.size())# torch.Size([-1, 256, 4, 13])\n",
    "        \n",
    "        batch = batch.permute(0, 3, 1, 2) # [batch_size, width, channels, height]\n",
    "        # print(batch.size()) # torch.Size([-1, 13, 256, 4])\n",
    "        \n",
    "        batch_size = batch.size(0)\n",
    "        T = batch.size(1)\n",
    "        batch = batch.view(batch_size, T, -1) # [batch_size, T==width, num_features==channels*height]\n",
    "        # print(batch.size()) # torch.Size([-1, 13, 1024])\n",
    "        \n",
    "        batch = self.linear1(batch)\n",
    "        batch = self.dp2(batch)\n",
    "        # print(batch.size()) # torch.Size([-1, 13, 256])\n",
    "        \n",
    "        batch, hidden = self.rnn1(batch)\n",
    "        feature_size = batch.size(2)\n",
    "        batch = batch[:, :, :feature_size//2] + batch[:, :, feature_size//2:]\n",
    "        # print(batch.size()) # torch.Size([-1, 13, 256])\n",
    "        \n",
    "        batch, hidden = self.rnn2(batch)\n",
    "        batch = self.dp3(batch)\n",
    "        # print(batch.size()) # torch.Size([-1, 13, 512])\n",
    "        \n",
    "        batch = self.linear2(batch)\n",
    "        # print(batch.size()) # torch.Size([-1, 13, 375])\n",
    "        \n",
    "        batch = batch.permute(1, 0, 2) # [T, batch_size, num_classes==num_features]\n",
    "        # print(batch.size()) # torch.Size([13, -1, 375])\n",
    "        \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if type(m) in [nn.Linear, nn.Conv2d, nn.Conv1d]:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crnn = CRNN(num_chars=len(char2idx), rnn_hidden_size=256)\n",
    "#crnn.apply(weights_init)\n",
    "crnn = crnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch_logits = crnn(image_batch.to(device))\n",
    "print(text_batch)\n",
    "print(text_batch_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_batch_logits.log_softmax(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CTCLoss(blank=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text_batch(text_batch):\n",
    "    \n",
    "    text_batch = [tokenize(text) for text in text_batch]\n",
    "    text_batch_targets_lens = [len(text) for text in text_batch]\n",
    "    text_batch_targets_lens = torch.IntTensor(text_batch_targets_lens)\n",
    "    \n",
    "    text_batch_concat = []\n",
    "    for text in text_batch:\n",
    "        for token in text:\n",
    "            text_batch_concat.append(token)\n",
    " \n",
    "    text_batch_targets = [char2idx[c] for c in text_batch_concat]\n",
    "    text_batch_targets = torch.IntTensor(text_batch_targets)\n",
    "    \n",
    "    return text_batch_targets, text_batch_targets_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(text_batch, text_batch_logits):\n",
    "    \"\"\"\n",
    "    text_batch: list of strings of length equal to batch size\n",
    "    text_batch_logits: Tensor of size([T, batch_size, num_classes])\n",
    "    \"\"\"\n",
    "    text_batch_logps = F.log_softmax(text_batch_logits, 2) # [T, batch_size, num_classes]  \n",
    "    text_batch_logps_lens = torch.full(size=(text_batch_logps.size(1),), \n",
    "                                       fill_value=text_batch_logps.size(0), \n",
    "                                       dtype=torch.int32).to(device) # [batch_size] \n",
    "    #print(text_batch_logps.shape)\n",
    "    #print(text_batch_logps_lens) \n",
    "    text_batch_targets, text_batch_targets_lens = encode_text_batch(text_batch)\n",
    "    #print(text_batch_targets)\n",
    "    #print(text_batch_targets_lens)\n",
    "    loss = criterion(text_batch_logps, text_batch_targets, text_batch_logps_lens, text_batch_targets_lens)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_loss(text_batch, text_batch_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters: Data Loading\n",
    "batch_size = 64\n",
    "\n",
    "# Hyperparameters: Model Architecture\n",
    "rnn_hidden_size = 256\n",
    "\n",
    "# Hyperparameters: Training\n",
    "num_epochs = 100\n",
    "lr = 0.001\n",
    "weight_decay = 1e-5\n",
    "clip_norm = 5\n",
    "step_size = 5\n",
    "gamma = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = IndianSceneTextDataset(train_dir) \n",
    "valset = IndianSceneTextDataset(val_dir) \n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=os.cpu_count(), shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, num_workers=os.cpu_count(), shuffle=False)\n",
    "\n",
    "crnn = CRNN(num_chars=len(char2idx), rnn_hidden_size=rnn_hidden_size)\n",
    "#crnn.apply(weights_init)\n",
    "crnn = crnn.to(device)\n",
    "\n",
    "optimizer = optim.Adam(crnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_losses = []\n",
    "epoch_losses_val = []\n",
    "iteration_losses = []\n",
    "num_updates_epochs = []\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    epoch_loss_list = [] \n",
    "    epoch_loss_list_val = []\n",
    "    num_updates_epoch = 0\n",
    "\n",
    "    crnn.train()\n",
    "    for image_batch, text_batch, image_fn_batch in tqdm(train_loader, leave=False, desc=\"Train\"):\n",
    "        optimizer.zero_grad()\n",
    "        text_batch_logits = crnn(image_batch.to(device))\n",
    "        loss = compute_loss(text_batch, text_batch_logits)\n",
    "        iteration_loss = loss.item()\n",
    "        if np.isnan(iteration_loss) or np.isinf(iteration_loss):\n",
    "            continue\n",
    "          \n",
    "        num_updates_epoch += 1\n",
    "        iteration_losses.append(iteration_loss)\n",
    "        epoch_loss_list.append(iteration_loss)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(crnn.parameters(), clip_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "    crnn.eval()\n",
    "    for image_batch, text_batch, image_fn_batch in tqdm(val_loader, leave=False, desc=\"Val\"):\n",
    "        text_batch_logits = crnn(image_batch.to(device))\n",
    "        loss = compute_loss(text_batch, text_batch_logits)\n",
    "        iteration_loss = loss.item()\n",
    "        if np.isnan(iteration_loss) or np.isinf(iteration_loss):\n",
    "            continue\n",
    "        epoch_loss_list_val.append(iteration_loss)\n",
    "\n",
    "\n",
    "    epoch_loss = np.mean(epoch_loss_list)\n",
    "    epoch_loss_val = np.mean(epoch_loss_list_val)\n",
    "    print(\"Epoch:{}    TrainLoss:{}    ValLoss:{}    NumUpdates:{}    LR:{}\".\\\n",
    "          format(epoch, epoch_loss, epoch_loss_val, num_updates_epoch, optimizer.param_groups[0]['lr']))\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    epoch_losses_val.append(epoch_loss_val)\n",
    "    num_updates_epochs.append(num_updates_epoch)\n",
    "    lr_scheduler.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        model_path = f'Models/{language}-Unicode-e{epoch}.pth'\n",
    "        torch.save(crnn.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'Models/{language}-Unicode.pth'\n",
    "torch.save(crnn.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "ax1.plot(iteration_losses)\n",
    "ax1.set_xlabel(\"Iterations\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "\n",
    "ax2.plot(epoch_losses, label=\"Train Loss\")\n",
    "ax2.plot(epoch_losses_val, label=\"Val Loss\")\n",
    "ax2.set_xlabel(\"Epochs\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset = IndianSceneTextDataset(train_dir) \n",
    "#valset = IndianSceneTextDataset(val_dir)\n",
    "testset = IndianSceneTextDataset(test_dir) \n",
    "\n",
    "#train_loader = DataLoader(trainset, batch_size=batch_size, num_workers=os.cpu_count(), shuffle=False)\n",
    "#val_loader = DataLoader(valset, batch_size=batch_size, num_workers=os.cpu_count(), shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, num_workers=os.cpu_count(), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = f'Models/{language}-Unicode.pth'\n",
    "\n",
    "crnn = CRNN(len(char2idx), rnn_hidden_size=rnn_hidden_size)\n",
    "crnn.load_state_dict(torch.load(model_path))\n",
    "crnn = crnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(text_batch_logits):\n",
    "\n",
    "    text_batch_tokens = F.softmax(text_batch_logits, 2).argmax(2) # [T, batch_size]\n",
    "    text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "\n",
    "    text_batch_tokens_new = []\n",
    "    for text_tokens in text_batch_tokens:\n",
    "        text = [idx2char[idx] for idx in text_tokens]\n",
    "        text = \"\".join(text)\n",
    "        text_batch_tokens_new.append(text)\n",
    "\n",
    "    return text_batch_tokens_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(data_loader):\n",
    "    result = pd.DataFrame(columns=['image_fn', 'actual', 'prediction'])\n",
    "    with torch.no_grad():\n",
    "        for image_batch, text_batch, image_fn_batch in tqdm(data_loader, leave=False):\n",
    "            text_batch_logits = crnn(image_batch.to(device)) # [T, batch_size, num_classes==num_features]\n",
    "            text_batch_pred = decode_predictions(text_batch_logits.cpu())\n",
    "            #print(text_batch, text_batch_pred)\n",
    "            df = pd.DataFrame(columns=['actual', 'prediction'])\n",
    "            df['image_fn'] = image_fn_batch\n",
    "            df['actual'] = text_batch\n",
    "            df['prediction'] = text_batch_pred\n",
    "            result = pd.concat([result, df])\n",
    "    result = result.reset_index(drop=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = make_predictions(train_loader)\n",
    "val_result = make_predictions(val_loader)\n",
    "test_result = make_predictions(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_result.shape)\n",
    "print(val_result.shape)\n",
    "print(test_result.shape)\n",
    "train_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(text):\n",
    "    if len(text) > 1:\n",
    "        letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n",
    "    elif len(text) == 1:\n",
    "        letters = [text[0]]\n",
    "    else:\n",
    "        return \"\"\n",
    "    return \"\".join(letters)\n",
    "\n",
    "def correct_prediction(word):\n",
    "    parts = word.split(\"-\")\n",
    "    parts = [remove_duplicates(part) for part in parts]\n",
    "    corrected_word = \"\".join(parts)\n",
    "    return corrected_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result['prediction_corrected'] = train_result['prediction'].apply(correct_prediction)\n",
    "val_result['prediction_corrected'] = val_result['prediction'].apply(correct_prediction)\n",
    "test_result['prediction_corrected'] = test_result['prediction'].apply(correct_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result['actual_length'] = train_result['actual'].apply(len)\n",
    "val_result['actual_length'] = val_result['actual'].apply(len)\n",
    "test_result['actual_length'] = test_result['actual'].apply(len)\n",
    "\n",
    "train_result['prediction_length'] = train_result['prediction_corrected'].apply(len)\n",
    "val_result['prediction_length'] = val_result['prediction_corrected'].apply(len)\n",
    "test_result['prediction_length'] = test_result['prediction_corrected'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(row):\n",
    "    \n",
    "    s1 = row['actual']\n",
    "    s2 = row['prediction_corrected']\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result['edit_distance'] = train_result.progress_apply(levenshteinDistance, axis=1)\n",
    "val_result['edit_distance'] = val_result.apply(levenshteinDistance, axis=1)\n",
    "test_result['edit_distance'] = test_result.apply(levenshteinDistance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result.actual_length.quantile([0.9, 0.99, 0.999])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy = accuracy_score(train_result['actual'], train_result['prediction_corrected'])\n",
    "val_accuracy = accuracy_score(val_result['actual'], val_result['prediction_corrected'])\n",
    "test_accuracy = accuracy_score(test_result['actual'], test_result['prediction_corrected'])\n",
    "print(train_accuracy, val_accuracy, test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_edit_distance in range(3+1):\n",
    "    print(\"Max Edit Distance\", max_edit_distance)\n",
    "    train_accuracy = (train_result['edit_distance'] <= max_edit_distance).sum() / len(train_result)\n",
    "    val_accuracy = (val_result['edit_distance'] <= max_edit_distance).sum() / len(val_result)\n",
    "    test_accuracy = (test_result['edit_distance'] <= max_edit_distance).sum() / len(test_result)\n",
    "    print(train_accuracy, val_accuracy, test_accuracy)\n",
    "    print(\"*\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_misclassifications(split='Train', num_samples=20, max_edit_distance=2):\n",
    "    \n",
    "    if split == 'Train':\n",
    "        result = train_result\n",
    "    elif split == 'Val':\n",
    "        result = val_result\n",
    "    elif split == 'Test':\n",
    "        result = test_result\n",
    "        \n",
    "    mask = result['edit_distance'] >= max_edit_distance\n",
    "    result = result[mask].sample(n = num_samples)\n",
    "    for row_id, row in result.iterrows():\n",
    "        info = 'Actual:', row['actual'], 'Prediction:', row['prediction'], \\\n",
    "              'Prediction Corrected:', row['prediction_corrected']\n",
    "        print(info)\n",
    "        \n",
    "        image_fp = f'Data/{language}/{split}/{row[\"image_fn\"]}'\n",
    "        plt.imshow(Image.open(image_fp))\n",
    "        plt.axis(False)\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_misclassifications('Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_misclassifications('Val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_misclassifications('Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "[1] https://github.com/carnotaur/crnn-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss cannot be reduced beyond 0.28 in val set (after 20 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
